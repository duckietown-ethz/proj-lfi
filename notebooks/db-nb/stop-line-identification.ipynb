{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from image_geometry import PinholeCameraModel\n",
    "from sensor_msgs.msg import CameraInfo\n",
    "from duckietown_utils.yaml_wrap import yaml_load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare visualisation tools\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bgrshow(bgr, size=(10,4)):\n",
    "    imshow(cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB), size=size)\n",
    "    \n",
    "def imshow(img, size=(10,4), cmap='viridis'):\n",
    "    plt.figure(figsize=size, dpi= 80, facecolor='w', edgecolor='k')\n",
    "    plt.imshow(img, cmap = cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Load jpegs\n",
    "import glob\n",
    "raw = []\n",
    "for im_path in sorted(glob.glob(\"frames/*.png\")):\n",
    "    bgr = cv2.imread(im_path,cv2.IMREAD_COLOR)\n",
    "    raw.append(bgr)\n",
    "    \n",
    "# loads stopline coordinates wrt intersection frame\n",
    "map_features = yaml_load_file('map/stoplines.yaml')\n",
    "map_pts = map_features.values()[0]\n",
    "map_sgs = map_features.values()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the AI filter\n",
    "from AntiInstagram import AntiInstagram\n",
    "ai = AntiInstagram()\n",
    "\n",
    "output_scale = 0.5\n",
    "color_balance_percentage = 0.8\n",
    "\n",
    "try:\n",
    "    raw0 = raw[0]\n",
    "except (NameError, IndexError) as e:    \n",
    "    print(\"No image in raw[0] to calibrate AI filter\")\n",
    "else:\n",
    "    ai.calculate_color_balance_thresholds(raw0, output_scale, color_balance_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = np.array([-3.589767590401803e-05, -0.00023491693147080584, -0.1374201532070648,\n",
    "               0.0008247535901185687, -5.00225097638814e-06,   -0.2685590146427659, \n",
    "              -5.664504414708967e-05, -0.006300114132830898,    1.0])\n",
    "H = np.reshape(H,(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_info_from_yaml(filename):\n",
    "    calib_data = yaml_load_file(filename)\n",
    "    cam_info = CameraInfo()\n",
    "    cam_info.width = calib_data['image_width']\n",
    "    cam_info.height = calib_data['image_height']\n",
    "    cam_info.K = calib_data['camera_matrix']['data']\n",
    "    cam_info.D = calib_data['distortion_coefficients']['data']\n",
    "    cam_info.R = calib_data['rectification_matrix']['data']\n",
    "    cam_info.P = calib_data['projection_matrix']['data']\n",
    "    cam_info.distortion_model = calib_data['distortion_model']\n",
    "    return cam_info\n",
    "\n",
    "def make_undistort_maps(ci):\n",
    "    K = np.array(ci.K).reshape((3,3))\n",
    "    D = np.array(ci.D).reshape((1,5))\n",
    "    R = np.array(ci.R).reshape((3,3))\n",
    "    P = np.array(ci.P).reshape((3,4))\n",
    "    mapx = np.ndarray(shape=(ci.height, ci.width, 1), dtype='float32')\n",
    "    mapy = np.ndarray(shape=(ci.height, ci.width, 1), dtype='float32')\n",
    "    mapx, mapy = cv2.initUndistortRectifyMap(K, D, R, P, \n",
    "                     (ci.width, ci.height), cv2.CV_32FC1, mapx, mapy)\n",
    "    return mapx, mapy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = camera_info_from_yaml('old_intrinsics.yaml')\n",
    "mapx, mapy = make_undistort_maps(ci)\n",
    "pcm = PinholeCameraModel()\n",
    "pcm.fromCameraInfo(ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_red1 = np.array([  0,140,100])\n",
    "hsv_red2 = np.array([ 15,255,255])\n",
    "hsv_red3 = np.array([165,140,100])\n",
    "hsv_red4 = np.array([180,255,255])\n",
    "cutoff   = 0\n",
    "# input is full res raw bitmaps\n",
    "# output is full res rectified, cropped, stop lines\n",
    "\n",
    "def preprocess(img, **kwargs):\n",
    "    rectarg = kwargs.get('rectify')\n",
    "    if rectarg:\n",
    "        rect = rectify(img)  # rectify\n",
    "    else:\n",
    "        rect = img\n",
    "    crpd = rect[cutoff:]  # crop\n",
    "    aied = ai.apply_color_balance(crpd, output_scale)  # color balance\n",
    "    hsv = cv2.cvtColor(aied, cv2.COLOR_BGR2HSV)       \n",
    "    bw1 = cv2.inRange(hsv, hsv_red1, hsv_red2)\n",
    "    bw2 = cv2.inRange(hsv, hsv_red3, hsv_red4)\n",
    "    red = cv2.bitwise_or(bw1, bw2)  # select red       \n",
    "    return red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nice to always have at hand\n",
    "reds = []\n",
    "for rawi in raw[:]:\n",
    "    reds.append(preprocess(rawi, rectify = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin: (x,y) axle coordinates (meters) of the near-left corner of the square\n",
    "# side:   side in meters of square on the ground \n",
    "# w:      side in pixels of the output image\n",
    "def rect2bird(image, origin, side, w):\n",
    "    # H assumes incoming image resolution is VGA (640x480) use output_scale if not.\n",
    "    # pixel at bottom center is x: 0.128 y: 0.00344677851347 #depends on cali\n",
    "    # x axis is longitudinal, y axis is to the left\n",
    "    # bottom edge aligned\n",
    "    # don't think backwards\n",
    "    oh, ow = np.shape(image) #original width, original height\n",
    "    side = float(side)\n",
    "    x0 = origin[0]\n",
    "    y0 = origin[1]+side/2\n",
    "    res = float(w)/side #pix/m in square\n",
    "    \n",
    "    output = np.zeros((w, w), dtype = np.uint8)\n",
    "    # loop over input image pixels\n",
    "    for row in range(oh):\n",
    "        for column in range(ow):\n",
    "            if image[row, column] == 0: \n",
    "                # if pixel is OFF skip it\n",
    "                continue\n",
    "            # if pixel is ON find out where it belongs on our output square\n",
    "            px = (column/output_scale, row/output_scale+cutoff)\n",
    "            gnd = rect2axle(px)\n",
    "            # now I have ground plane coordinates wrt axle frame\n",
    "            # find correpsonding pixel in square (\"ground pixel x and y\")\n",
    "            gpx = int(w-(gnd[0] - x0)*res) # column\n",
    "            gpy = int( -(gnd[1] - y0)*res) # row\n",
    "\n",
    "            if gpx < w and gpx >= 0 and gpy < w and gpy >= 0:\n",
    "                output[gpx, gpy] = image[row, column]\n",
    "    return output\n",
    "\n",
    "# Rectifies image using pinhole camera model\n",
    "def rectify(cv_image_raw):\n",
    "    cv_image_rectified = np.zeros_like(cv_image_raw)\n",
    "    if np.shape(cv_image_raw)\n",
    "    mapx, mapy = cv2.initUndistortRectifyMap(K, D, R, P, \n",
    "                     (ci.width, ci.height), cv2.CV_32FC1, mapx, mapy)\n",
    "\n",
    "    return cv2.remap(cv_image_raw, mapx, mapy, cv2.INTER_NEAREST, cv_image_rectified)\n",
    "\n",
    "# shortcut for a frequent use case of the two above\n",
    "def bird(img):\n",
    "    h,w = np.shape(img)\n",
    "    rect = rectify(img)\n",
    "    rect[:,(0,w-1)] = 128\n",
    "    rect[(0,h-1),:] = 128\n",
    "    bev = rect2bird(rect,[0, 0], 1.00, 480)\n",
    "    return bev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RULE pixel coordinates are tuples, points are arrays\n",
    "\n",
    "# axle to rectified pixel coordinates\n",
    "def axle2rect(point):\n",
    "    ground_point = np.array([point[0], point[1], 1.0])\n",
    "    image_point = np.linalg.solve(H, ground_point)\n",
    "    image_point = image_point / image_point[2]\n",
    "\n",
    "    return (image_point[0], image_point[1])\n",
    "\n",
    "def rect2axle(rpx):\n",
    "    rpx = np.array([rpx[0], rpx[1], 1.0])\n",
    "    gp = np.dot(H, rpx)\n",
    "    return np.array([gp[0]/gp[2], gp[1]/gp[2], 0.0])\n",
    "\n",
    "# pts are lists\n",
    "def cam2dist(pts):\n",
    "    rvec = tvec = np.array([[0,0,0]], dtype='float')\n",
    "    K = pcm.intrinsicMatrix()\n",
    "    D = pcm.distortionCoeffs()\n",
    "    ptsOut, _ = cv2.projectPoints(np.array(pts, dtype='float'), rvec, tvec, K, D)\n",
    "    return ptsOut[:,0,:].tolist()\n",
    "\n",
    "        \n",
    "# same as above but doesn't apply distortion    \n",
    "def cam2rect(pts):\n",
    "    P = pcm.projectionMatrix()\n",
    "    pr = []\n",
    "    for pt in pts:\n",
    "        pt = np.concatenate([np.array(pt), [1]])\n",
    "        pri = np.dot(P, pt).tolist()[0]\n",
    "        pr.append(pri)\n",
    "    return pr\n",
    "\n",
    "def rect2cam(pr):\n",
    "    uv = pcm.projectPixelTo3dRay(pr)\n",
    "    return np.array([uv[0]/uv[2], uv[1]/uv[2], 1.0])\n",
    "\n",
    "def rect2dist(rpx):\n",
    "    cpt = rect2cam(rpx)\n",
    "    return cam2dist(cpt)\n",
    "\n",
    "def dist2rect(dist):\n",
    "    #print(\"dist:\",dist,\"type:\",type(dist))\n",
    "    return pcm.rectifyPoint(dist)\n",
    "\n",
    "from numpy import sin, cos, pi\n",
    "# pose is (x,y,theta) - (0,0,0) is the target exit pose. \n",
    "def axle2intersection(g, pose):\n",
    "    g = np.array([g[0],g[1]])\n",
    "    t = pose[2]\n",
    "    d = np.array([pose[0],pose[1]])\n",
    "    R = [[cos(t), -sin(t)],[sin(t), cos(t)]]\n",
    "    i = np.dot(R,g)\n",
    "    return i + d\n",
    " \n",
    "def intersection2axle(pt, pose):\n",
    "    pt=[pt[0],pt[1]]\n",
    "    t = pose[2]\n",
    "    d = np.array([pose[0],pose[1]])\n",
    "    R = [[cos(t), sin(t)],[-sin(t), cos(t)]]\n",
    "    i = np.dot(R, pt-d)\n",
    "    return np.array([i[0],i[1],0.0])   \n",
    "\n",
    "def intersection2rect(pt, pose):\n",
    "    gnd = intersection2axle(pt, pose)\n",
    "    return axle2rect(gnd)\n",
    "\n",
    "def rect2intersection(px, pose):\n",
    "    gnd = rect2axle(px)\n",
    "    return axle2intersection(gnd, pose)\n",
    "\n",
    "def dist2intersection(dpt,pose):\n",
    "    #print(\"pose:\",pose,\"type:\",type(pose))\n",
    "    #print(\"dpt:\",dpt,\"type:\",type(dpt))\n",
    "\n",
    "    rpt = dist2rect(dpt)\n",
    "    pt = rect2intersection(rpt, pose)\n",
    "    return pt\n",
    "\n",
    "def intersection2dist(pt,pose):\n",
    "    ipt = intersection2rect(pt,pose)\n",
    "    cpt = rect2cam(ipt)\n",
    "    dpt = cam2dist([cpt])[0]\n",
    "    idpt = (int(dpt[0]), int(dpt[1]))\n",
    "    return idpt\n",
    "\n",
    "# input: gnd:    (x,y) coordinates of point in intersection coordinates\n",
    "#        origin: (x,y) origin of the birds eye view in axle coordinates\n",
    "#        side:   side of the square captured in the birds eye view \n",
    "#        w:      width (equal to height) of the birds eye view image\n",
    "# output: pixel coordinates of the point in the birds-eye-view \n",
    "def intersection2bird(gnd, pose, origin, side, w):\n",
    "    apt = intersection2axle(gnd, pose)\n",
    "    brd = axle2bird(apt,origin, side, w)\n",
    "    return brd\n",
    "\n",
    "# input: gnd:    (x,y) coordinates of point in axle coordinates\n",
    "#        origin: (x,y) origin of the birds eye view in axle coordinates\n",
    "#        side:   side of the square captured in the birds eye view \n",
    "#        w:      width (equal to height) of the birds eye view image\n",
    "# output: pixel coordinates of the point in the birds-eye-view \n",
    "def axle2bird(gnd, origin, side, w):\n",
    "    side = float(side)\n",
    "    x0 = origin[0]\n",
    "    y0 = origin[1]+side/2\n",
    "    res = float(w)/side # pix/m in square\n",
    "    # now I have ground plane coordinates wrt axel frame\n",
    "    # find correpsonding pixel in square (\"ground pixel x and y\")\n",
    "    gpv = int(w-(gnd[0] - x0)*res) #column\n",
    "    gpu = int(-(gnd[1] - y0)*res) #row\n",
    "    return (gpu, gpv)\n",
    "\n",
    "def dist2bird(dist, origin = [0,0], side=1.0, w=480):\n",
    "    r = dist2rect(dist)\n",
    "    a = rect2axle(r)\n",
    "    return axle2bird(a,origin, side, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = [-0.09, -.31, pi/2] # before right turn\n",
    "red = np.copy(reds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# red is latest, distorted stoplines image\n",
    "# prior is naively integrated pose\n",
    "def estimate(red, prior):\n",
    "    #1. given the expected pose, where do we expect the vertices to be?\n",
    "    #   - project the stopline points to the distorted image \n",
    "    intersection2dist(pt,pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior(pose):\n",
    "    hud_pts = dict()\n",
    "    for key in map_pts.keys():\n",
    "        hud_pts[key] = intersection2dist(map_pts[key][1], pose)\n",
    "    return hud_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_prior_approx(img, pose):\n",
    "    hud_pts = dict()\n",
    "    for key in map_pts.keys():\n",
    "        hud_pts[key] = intersection2dist(map_pts[key][1], pose)\n",
    "    for pt in hud_pts.values():\n",
    "        cv2.drawMarker(img, pt, (0,0,200), \n",
    "                       markerType=cv2.MARKER_SQUARE,\n",
    "                       markerSize=40, \n",
    "                       thickness =2, \n",
    "                       line_type =cv2.LINE_4)\n",
    "    return img\n",
    "\n",
    "def overlay_prior_bev_approx(bev, pose, orig, side, w):\n",
    "    bev_pts = dict()\n",
    "    for key in map_pts.keys():\n",
    "        hud_pts[key] = intersection2bird(map_pts[key][1], \n",
    "                                         pose,\n",
    "                                         orig,side,w\n",
    "                                        )\n",
    "        \n",
    "         \n",
    "    for pt in hud_pts.values():\n",
    "        cv2.drawMarker(bev, pt, (120,0,100), \n",
    "                       markerType=cv2.MARKER_SQUARE,\n",
    "                       markerSize=20, \n",
    "                       thickness =1, \n",
    "                       line_type =cv2.LINE_4)\n",
    "    return bev\n",
    "\n",
    "def overlay_prior(img, pose):\n",
    "    hud_pts = dict()\n",
    "    for key in map_pts.keys():\n",
    "        hud_pts[key] = intersection2dist(map_pts[key][1], pose)\n",
    "    for pt in hud_pts.values():\n",
    "        cv2.drawMarker(img, pt, (100,100,0), \n",
    "                       markerType=cv2.MARKER_SQUARE,\n",
    "                       markerSize=40, \n",
    "                       thickness =2, \n",
    "                       line_type =cv2.LINE_4)\n",
    "    return img\n",
    "\n",
    "def overlay_prior_bev(bev, pose, orig, side, w):\n",
    "    bev_pts = dict()\n",
    "    for key in map_pts.keys():\n",
    "        bev_pts[key] = intersection2bird(map_pts[key][1], \n",
    "                                         pose,\n",
    "                                         orig,side,w)\n",
    "    for pt in bev_pts.values():\n",
    "        cv2.drawMarker(bev, pt, (200,0,200), \n",
    "                       markerType=cv2.MARKER_SQUARE,\n",
    "                       markerSize=20, \n",
    "                       thickness =1, \n",
    "                       line_type =cv2.LINE_4)\n",
    "    return bev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcorners(img,radius=35):\n",
    "    kpcoords = detect_corners(img)\n",
    "    threshold = radius**2\n",
    "    bins = [] #list of lists of tuples\n",
    "    for k in kpcoords:\n",
    "        placed = False\n",
    "        for b in bins:\n",
    "            if (k[0]-b[0][0])**2 + (k[1]-b[0][1])**2 < threshold:\n",
    "                b.append(k)\n",
    "                placed = True\n",
    "                break\n",
    "        if not placed:\n",
    "            bins.append([k])  \n",
    "    return bins\n",
    "\n",
    "# takes rectified images, finds features, then projects the features only\n",
    "def getcorners_bev(dist_img,radius=40,viz=False):\n",
    "    kpdist = detect_corners(dist_img,viz=viz)\n",
    "    kpbev = [dist2bird(kd) for kd in kpdist]\n",
    "    threshold = radius**2\n",
    "    bins = [] #list of lists of tuples\n",
    "    for k in kpbev:\n",
    "        placed = False\n",
    "        for b in bins:\n",
    "            if (k[0]-b[0][0])**2 + (k[1]-b[0][1])**2 < threshold:\n",
    "                b.append(k)\n",
    "                placed = True\n",
    "                break\n",
    "        if not placed:\n",
    "            bins.append([k])   \n",
    "    return bins\n",
    "\n",
    "# takes kp in pixel coordinates for img\n",
    "def overlay_kp(img, kpcoords, color = (100,100,100)):\n",
    "    out = np.copy(img)\n",
    "    for kp in kpcoords:\n",
    "        pix  = (int(kp[0]),int(kp[1]))\n",
    "        cv2.drawMarker(out, pix, color, \n",
    "                       markerType=cv2.MARKER_SQUARE, \n",
    "                       markerSize=10, thickness=1, line_type=cv2.LINE_4)\n",
    "    return out\n",
    "\n",
    "# takes bev image, kp in distorted coordinates \n",
    "def overlay_kp_bev(bev, kpcoords, outlist=None, color = (100,100,100)):\n",
    "    brdpts = []\n",
    "    for kp in kpcoords:\n",
    "        brdpts.append(dist2bird(kp, [0, 0], 1.00, 480))\n",
    "        if outlist is not None:\n",
    "            outlist.append(brdpts)\n",
    "    out = overlay_kp(bev,brdpts,color=color)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda a:[k for b in a for k in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = [0.01, 0.01, 0.10] #m m rad\n",
    "def disturb(pose):\n",
    "        return pose + np.random.randn(3)*sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "red = np.copy(reds[0])\n",
    "\n",
    "kpcoords = detect_corners(red, viz=False, scale=1.0/3)\n",
    "\n",
    "pose = np.array([-0.09, -.31, pi/2]) # before right turn\n",
    "naivepose = disturb(pose)\n",
    " \n",
    "print(np.shape(red))\n",
    "bev = bird(red)\n",
    "imshow(bev)\n",
    "\n",
    "#bev = overlay_kp_bev(bev, kpcoords)\n",
    "bev = overlay_prior_bev(bev, naivepose, [0, 0], 1.00, 480)\n",
    "print(np.unique(bev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast = cv2.FastFeatureDetector_create(nonmaxSuppression = False,\n",
    "                                     #type=cv2.FAST_FEATURE_DETECTOR_TYPE_9_16,\n",
    "                                      \n",
    "                                      #type=cv2.FAST_FEATURE_DETECTOR_TYPE_5_8,\n",
    "                                      #type=cv2.FAST_FEATURE_DETECTOR_TYPE_7_12,\n",
    "                                      threshold = 75\n",
    "                                     )\n",
    "def detect_corners(red, **kwargs):\n",
    "    viz = kwargs.get('viz')\n",
    "    scale = kwargs.get('scale')\n",
    "    if scale is None:\n",
    "        scale = 1.0/1\n",
    "    h,w = np.shape(red)\n",
    "    red = cv2.resize(red, \n",
    "                     (int(w*scale), int(h*scale)), \n",
    "                      interpolation = cv2.INTER_NEAREST)\n",
    "    red = cv2.GaussianBlur(red, (3,3), 2)\n",
    "    kps = fast.detect(red, None)\n",
    "    if viz:\n",
    "        imshow(cv2.drawKeypoints(red, kps, None, color=(255,0,0)))\n",
    "    kpcoords = []\n",
    "    for kp in kps:\n",
    "        kpcoords.append((kp.pt[0]/scale, kp.pt[1]/scale))\n",
    "        #print(kp.pt)\n",
    "    return kpcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dimg in reds[0:1]:\n",
    "    ms = []\n",
    "    radius = 10\n",
    "    bevbins = getcorners_bev(dimg, radius, viz=True)\n",
    "    #bevbins = [[dist2bird(k) for k in db] for db in dbins]\n",
    "    bev = bird(dimg)\n",
    "    nbins = len(bevbins)\n",
    "    print(nbins,': ')\n",
    "    colstep = 255/(nbins+1)\n",
    "    col = colstep\n",
    "    for b in bevbins:\n",
    "        print(\"n=\",len(b),\"\\tmiddle=\",end='')\n",
    "        m = np.mean(b,axis=0)\n",
    "        print(m) \n",
    "        ms.append(m)\n",
    "        bev = overlay_kp(bev, b, color = (col,0,0))\n",
    "\n",
    "        col += colstep\n",
    "    imshow(bev,size=(10,10),cmap='tab20')\n",
    "\n",
    "    #bev = overlay_kp(bev, flatten(bevbins))\n",
    "#dbins = getcorners(dimg)\n",
    "#for b in dbins:\n",
    "#    imshow(overlay_kp(dimg, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9192b8fb4c63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Read image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#raw[0])#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Detect blobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw' is not defined"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# Standard imports\n",
    "import cv2\n",
    "import numpy as np;\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# Setup SimpleBlobDetector parameters.\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# Change thresholds\n",
    "params.minThreshold = 0\n",
    "params.maxThreshold = 80\n",
    "# Filter by Area.\n",
    "params.filterByArea = True\n",
    "params.minArea = 25\n",
    "\n",
    "# Filter by Circularity\n",
    "params.filterByCircularity = False\n",
    "#params.minCircularity = 0.1\n",
    "\n",
    "# Filter by Convexity\n",
    "params.filterByConvexity = False\n",
    "#params.minConvexity = 0.87\n",
    "\n",
    "# Filter by Inertia\n",
    "params.filterByInertia = False\n",
    "#params.minInertiaRatio = 0.01\n",
    "\n",
    "# Create a detector with the parameters\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "\n",
    "# Read image\n",
    "for r in raw:\n",
    "    im = np.copy(255-preprocess(r))#raw[0])#\n",
    "    # Detect blobs.\n",
    "    keypoints = detector.detect(im)\n",
    "    #print(keypoints)\n",
    "    #imshow(im)\n",
    "    # Draw detected blobs as red circles.\n",
    "    # cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures\n",
    "    # the size of the circle corresponds to the size of blob\n",
    "    im_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (255,0,0), \n",
    "                                          cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    titles = ['Blobs Detected']\n",
    "    images = [im_with_keypoints]\n",
    "\n",
    "\n",
    "    for i in xrange(1):    \n",
    "        plt.subplot(1,1,i+1), plt.imshow(images[i],'gray')\n",
    "        plt.title(titles[i])\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "red = np.copy(reds[0])\n",
    "\n",
    "kpcoords = detect_corners(red, viz = True,)\n",
    "\n",
    "\n",
    "imshow(kpimg)\n",
    "\n",
    "kpint = []\n",
    "for kp in kpcoords:\n",
    "    kpint = dist2intersection(kp, pose)\n",
    "rect = rectify(kpimg)\n",
    "imshow(rect)\n",
    "rect[:,(0,640-1)] = 128\n",
    "rect[(0,480-1),:] = 128\n",
    "\n",
    "bev = rect2bird(rect[:,:,1],[0, 0], 1.00, 480)\n",
    "\n",
    "gp = []\n",
    "for kp in kpcoords:\n",
    "    kpr = dist2rect(kp)\n",
    "    g = rect2axle(kpr)\n",
    "    gp.append(axle2bird(g,[0, 0], 1.00, 480))\n",
    "\n",
    "for i in range(len(gp)):\n",
    "    cv2.drawMarker(bev, gp[i], (100,0,0), \n",
    "                   markerType=cv2.MARKER_STAR, \n",
    "               markerSize=10, thickness=1, line_type=cv2.LINE_AA)\n",
    "\n",
    "imshow(overlay_prior_bev(bev, naivepose, [0, 0], 1.00, 480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kpint = []\n",
    "for kpc in kpcoords:\n",
    "    kpi = dist2intersection(kpc, pose)\n",
    "    kpint.append(kpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise  # OLD CODE\n",
    "dis = np.copy(reds[0])\n",
    "for pt in hud_pts.values():\n",
    "    cv2.drawMarker(dis, pt, (128,0,0), \n",
    "                   markerType=cv2.MARKER_STAR,\n",
    "               markerSize=40, thickness=1, line_type=cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise # OLD CODE\n",
    "\n",
    "\n",
    "### works on absolute image pixel values\n",
    "# BEWARE ARTIFACTS if you try to draw outside of the image bounds\n",
    "def draw_segment(image, pt0, pt1, color):\n",
    "    pt0 = (int(pt0[0]), int(pt0[1]))\n",
    "    pt1 = (int(pt1[0]), int(pt1[1]))\n",
    "    defined_colors = {\n",
    "        'red': ['rgb', [1, 0, 0]],\n",
    "        'green': ['rgb', [0, 1, 0]],\n",
    "        'blue': ['rgb', [0, 0, 1]],\n",
    "        'yellow': ['rgb', [1, 1, 0]],\n",
    "        'magenta': ['rgb', [1, 0, 1]],\n",
    "        'cyan': ['rgb', [0, 1, 1]],\n",
    "        'white': ['rgb', [1, 1, 1]],\n",
    "        'black': ['rgb', [0, 0, 0]]}\n",
    "    _color_type, [r, g, b] = defined_colors[color]\n",
    "    cv2.line(image, pt0, pt1, (b * 128, g * 128, r * 128), 3)\n",
    "    return image\n",
    "\n",
    "# takes RECTIFIED image and robot pose wrt intersection ref frame\n",
    "# return the rectified image with stop lines superimposed\n",
    "def overlay(img, pose):\n",
    "    # use pose to transform the overlay\n",
    "    for seg in map_sgs:\n",
    "        pt0 = intersection2rect(map_pts[seg['points'][0]][1],pose)\n",
    "        pt1 = intersection2rect(map_pts[seg['points'][1]][1],pose)\n",
    "        #print(pt0, \" - \", pt1)\n",
    "        col = 'white'#seg['color']\n",
    "        img = draw_segment(img, pt0, pt1, col)\n",
    " \n",
    "    return img\n",
    "# takes DISTORTED image and robot pose wrt intersection ref frame\n",
    "# return the rectified image with stop lines superimposed\n",
    "def dist_overlay(img, pose):\n",
    "    # use pose to transform the overlay\n",
    "    for seg in map_sgs:\n",
    "        pt0 = intersection2dist(map_pts[seg['points'][0]][1],pose)\n",
    "        pt1 = intersection2dist(map_pts[seg['points'][1]][1],pose)\n",
    "        #print(pt0, \" - \", pt1)\n",
    "        col = 'white'#seg['color']\n",
    "        img = draw_segment(img, pt0, pt1, col)\n",
    "    # print('segments will be straight, corners have been distorted')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.copy(raw[0])\n",
    "rect = rectify(img)\n",
    "pose = [-0.09, -.31, pi/2] # before right turn\n",
    "hud = overlay(rect, pose)\n",
    "bgrshow(hud)\n",
    "dist_hud = dist_overlay(img, pose)\n",
    "bgrshow(dist_hud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = reds[0]\n",
    "\n",
    "ddepth = cv2.CV_16S\n",
    "grad_x = cv2.Sobel(red, ddepth, 1, 0, ksize=-1, scale=1, borderType=cv2.BORDER_DEFAULT)\n",
    "grad_y = cv2.Sobel(red, ddepth, 0, 1, ksize=-1, scale=1, borderType=cv2.BORDER_DEFAULT)\n",
    "grad = np.stack([grad_x,grad_y])\n",
    "print(np.shape(grad))\n",
    "#pcd =    cv2.preCornerDetect(red, ksize=11)\n",
    "#har =    cv2.cornerHarris(red, 10, ksize=11, k=10)\n",
    "\n",
    "evnv = cv2.cornerEigenValsAndVecs(red, blockSize=1, ksize=1) #(l1,l2,x1,y1,x2,y2)\n",
    "\n",
    "l1 = evnv[:,:,0]\n",
    "l2 = evnv[:,:,1]\n",
    "x1 = evnv[:,:,2]\n",
    "y1 = evnv[:,:,3]\n",
    "theta1 = np.arctan2(y1,x1)\n",
    "x2 = evnv[:,:,4]\n",
    "y2 = evnv[:,:,5]\n",
    "theta2 = np.arctan2(y2,x2)\n",
    "\n",
    "theta_grad = np.arctan2(grad[1],grad[0])\n",
    "\n",
    "#imshow(theta_grad)\n",
    "#imshow(grad_x)\n",
    "print(grad_x[300,300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispOpticalFlow( image,Flow ):\n",
    "    \n",
    "    h, w = np.shape(image)\n",
    "    mask = np.zeros_like(image)\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if Flow[0,i,j] != 0 or Flow[1,i,j] != 0:\n",
    "                if (i+j)%5 != 0: continue\n",
    "                j_ = int(j + 0.003*Flow[0,i,j])\n",
    "                i_ = int(i + 0.003*Flow[1,i,j])\n",
    "                i_ = np.clip(i_, 0, h)\n",
    "                j_ = np.clip(j_, 0, w)\n",
    "                mask = cv2.line(mask, (j,i),(j_,i_), [255, 255, 255], 1)\n",
    "    #superpose lines onto image\n",
    "    #img = cv2.add(image,mask)\n",
    "    #print image\n",
    "    imshow(mask)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = []\n",
    "for i in range(len(reds)-1):\n",
    "    deltas.append(reds[i] + 0.5*reds[i+1])\n",
    "    \n",
    "for delta in deltas:\n",
    "    imshow(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intp1 = [-0.21,0.12,0]\n",
    "intp2 = [0,0,0]\n",
    "pose = [-0.09, -.31, pi/2] # before right turn\n",
    "middle = intersection2axle(intp1,pose)\n",
    "target = intersection2axle(intp2,pose)\n",
    "\n",
    "# axle coordinates, xyz in meters\n",
    "# x forward, y left, z up\n",
    "gnd = [(0.128+0.04, 0.003+0.12, 0), middle, target]\n",
    "pr0 = []\n",
    "for g in gnd:\n",
    "    pr0.append(axle2rect(g)) # NOTE: you are rounding to integers but don't need to\n",
    "print('Rectified pixle coordinates = ', pr0)\n",
    "\n",
    "pts = []\n",
    "for pr0i in pr0:\n",
    "    pts.append(rect2cam(pr0i))\n",
    "print('Camera frame coordinates = ', pts)\n",
    "\n",
    "pd = cam2dist(pts)\n",
    "print('Distorted pixel coords = \\n', pd)\n",
    "\n",
    "pr = cam2rect(pts)\n",
    "print('Rectified pixel coord = \\n', pr)\n",
    "\n",
    "dis = np.copy(raw[0])\n",
    "for i in range(len(pd)):\n",
    "    cv2.drawMarker(dis, (int(pd[i][0]),int(pd[i][1])), (255,0,0), \n",
    "                   markerType=cv2.MARKER_STAR,\n",
    "               markerSize=40, thickness=3, line_type=cv2.LINE_AA)\n",
    " \n",
    "rec = rectify(dis)\n",
    "\n",
    "bgrshow(dis)\n",
    "\n",
    "for i in range(len(pr)):\n",
    "    cv2.drawMarker(rec, (int(pr[i][0]),int(pr[i][1])), (0,255,0), \n",
    "                   markerType=cv2.MARKER_STAR, \n",
    "               markerSize=20, thickness=1, line_type=cv2.LINE_AA)\n",
    "for i in range(len(pr)):\n",
    "    cv2.drawMarker(rec, (int(pr0[i][0]),int(pr0[i][1])), (255,255,0), \n",
    "                   markerType=cv2.MARKER_STAR, \n",
    "               markerSize=20, thickness=2, line_type=cv2.LINE_AA)\n",
    "\n",
    "bgrshow(rec)\n",
    "\n",
    "red = preprocess(dis)\n",
    "bev = rect2bird(red,[0, 0], 1.00, 480)\n",
    "\n",
    "gp = []\n",
    "for g in gnd:\n",
    "    gp.append(axle2bird(g,[0, 0], 1.00, 480))\n",
    "\n",
    "for i in range(len(gp)):\n",
    "    cv2.drawMarker(bev, (int(gp[i][0]),int(gp[i][1])), (255,255,255), \n",
    "                   markerType=cv2.MARKER_STAR, \n",
    "               markerSize=10, thickness=1, line_type=cv2.LINE_AA)\n",
    "\n",
    "imshow(bev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = cv2.resize(reds[0], (320,240))\n",
    "\n",
    "ddepth = cv2.CV_16S\n",
    "grad_x = cv2.Sobel(red, ddepth, 1, 0, ksize=-1, scale=1, borderType=cv2.BORDER_DEFAULT)\n",
    "grad_y = cv2.Sobel(red, ddepth, 0, 1, ksize=-1, scale=1, borderType=cv2.BORDER_DEFAULT)\n",
    "grad = np.stack([grad_x,grad_y])\n",
    "\n",
    "dispOpticalFlow(red, grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intp1 = [-0.21,0.12,0]\n",
    "intp2 = [0,0,0]\n",
    "pose = [-0.09, -.31, pi/2] # before right turn\n",
    "middle = intersection2axle(intp1,pose)\n",
    "target = intersection2axle(intp2,pose)\n",
    "\n",
    "# axle coordinates, xyz in meters\n",
    "# x forward, y left, z up\n",
    "gnd = [(0.128+0.04, 0.003+0.12, 0), middle, target]\n",
    "pr0 = []\n",
    "for g in gnd:\n",
    "    pr0.append(axle2rect(g)) # NOTE: you are rounding to integers but don't need to\n",
    "print('Rectified pixle coordinates = ', pr0)\n",
    "\n",
    "pts = []\n",
    "for pr0i in pr0:\n",
    "    pts.append(rect2cam(pr0i))\n",
    "print('Camera frame coordinates = ', pts)\n",
    "\n",
    "pd = cam2dist(pts)\n",
    "print('Distorted pixel coords = \\n', pd)\n",
    "\n",
    "pr = cam2rect(pts)\n",
    "print('Rectified pixel coord = \\n', pr)\n",
    "\n",
    "dis = np.copy(raw[0])\n",
    "for i in range(len(pd)):\n",
    "    cv2.drawMarker(dis, (int(pd[i][0]),int(pd[i][1])), (255,0,0), \n",
    "                   markerType=cv2.MARKER_STAR,\n",
    "               markerSize=40, thickness=3, line_type=cv2.LINE_AA)\n",
    "\n",
    "rec = rectify(dis)\n",
    "\n",
    "bgrshow(dis)\n",
    "\n",
    "for i in range(len(pr)):\n",
    "    cv2.drawMarker(rec, (int(pr[i][0]),int(pr[i][1])), (0,255,0), \n",
    "                   markerType=cv2.MARKER_STAR, \n",
    "               markerSize=20, thickness=1, line_type=cv2.LINE_AA)\n",
    "for i in range(len(pr)):\n",
    "    cv2.drawMarker(rec, (int(pr0[i][0]),int(pr0[i][1])), (255,255,0), \n",
    "                   markerType=cv2.MARKER_STAR, \n",
    "               markerSize=20, thickness=2, line_type=cv2.LINE_AA)\n",
    "\n",
    "bgrshow(rec)\n",
    "\n",
    "red = preprocess(dis)\n",
    "bev = rect2bird(red,[0, 0], 1.00, 480)\n",
    "\n",
    "gp = []\n",
    "for g in gnd:\n",
    "    gp.append(axle2bird(g,[0, 0], 1.00, 480))\n",
    "\n",
    "imshow(bev)    \n",
    "    \n",
    "for i in range(len(gp)):\n",
    "    cv2.drawMarker(bev, (int(gp[i][0]),int(gp[i][1])), (255,255,255), \n",
    "                   markerType=cv2.MARKER_STAR, \n",
    "               markerSize=10, thickness=1, line_type=cv2.LINE_AA)\n",
    "\n",
    "imshow(bev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = np.copy(reds[0])\n",
    "  \n",
    "kpcoords = detect_corners(red, viz=False, scale=1.0/3)\n",
    "\n",
    "pose = np.array([-0.09, -.31, pi/2]) # before right turn\n",
    "naivepose = disturb(pose)\n",
    "\n",
    "#kpimg = overlay_kp(red, kpcoords)\n",
    "#kpimg = overlay_prior(kpimg, naivepose)\n",
    "#imshow(kpimg)\n",
    "\n",
    "kpint = []\n",
    "for kpc in kpcoords:\n",
    "    kpi = dist2intersection(kpc, pose)\n",
    "    kpint.append(kpi)\n",
    "rect = rectify(red)\n",
    "rect[:,(0,640-1)] = 128\n",
    "rect[(0,480-1),:] = 128\n",
    "bev = rect2bird(rect[:,:],[0, 0], 1.00, 480)\n",
    "bev = overlay_kp_bev(bev, kpint)\n",
    "bev = overlay_prior_bev(bev, naivepose, [0, 0], 1.00, 480)\n",
    "imshow(bev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
